{
module Parse.ParseExpr where

import Unsafe.Coerce (unsafeCoerce)
import Data.List (intercalate)
import Data.Maybe (fromMaybe)
import Lex.Token (Token, tokenPos)
import Lex.Tokenizer (tokenizeWithNL)
import Parse.SyntaxTree
import Parse.ParserBasic
import Util.Exception (ErrorKind, makeError, expectedExpression, assignErrorMsg)
import Util.Type (Path)

import qualified Lex.Token as Lex
import qualified Util.Exception as UE
}

%name parseExpr Start
%tokentype { Token }
%error { parseExprError }

%token
    EOF                 { Lex.EOF _ }
    KW_TRUE             { Lex.Ident "true" _ }
    KW_FALSE            { Lex.Ident "false" _ }
    KW_AS               { Lex.Ident "as" _ }

    identity            { Lex.Ident $$ _ }
    number              { Lex.NumberConst $$ _ }
    character           { Lex.CharConst $$ _ }
    string              { Lex.StrConst $$ _ }

    '='                 { Lex.Symbol Lex.Assign _ }
    '+'                 { Lex.Symbol Lex.Plus _ }
    '-'                 { Lex.Symbol Lex.Minus _ }
    '*'                 { Lex.Symbol Lex.Multiply _ }
    '/'                 { Lex.Symbol Lex.Divide _ }
    '('                 { Lex.Symbol Lex.LParen _ }
    ')'                 { Lex.Symbol Lex.RParen _ }

    '.'                 { Lex.Symbol Lex.Dot _ }

%right '='
%left '+' '-'
%left '*' '/'
%right UPLUS UMINUS

%%

Start
    : Expr EOF { $1 }
    ;

#include "Parse/GrammarExpr.inc"

{
-- | Happy-required error continuation for expression parsing.
-- 
-- Happy enforces a polymorphic error handler of type:
--     [Token] -> a
--
-- However, our parser produces a concrete 'Expression' as the error result.
-- To bridge this mismatch, we deliberately use 'unsafeCoerce' here to coerce
-- an 'Expression' into the expected polymorphic return type.
--
-- This function should ONLY be used as the 'parseError' hook generated by Happy.
-- Any misuse outside the parser error path is undefined behavior.
parseExprError :: [Token] -> a
parseExprError toks = unsafeCoerce (mkHappyErrorExpr toks)


-- | High-level entry point for lexing + parsing a single expression.
--
-- This function performs the following pipeline:
--
--   1. Tokenize the input source string with newline inference.
--   2. If lexical errors exist, return them immediately.
--   3. Parse the token stream into an 'Expression'.
--   4. Traverse the resulting AST to collect embedded parse errors.
--   5. Convert all expression-level errors into unified 'ErrorKind's.
--
-- On success, returns:
--   Right Expression
--
-- On failure, returns:
--   Left [ErrorKind]
--
-- This design intentionally separates:
--   * lexing errors (returned directly)
--   * parsing errors (embedded in AST, then extracted)
lexparseExpr :: Path -> String -> Either [ErrorKind] Expression
lexparseExpr p str = let (errs, tokens) = tokenizeWithNL p str in case errs of
    [] -> let expr = parseExpr tokens in case getErrorProgram ([], [Expr expr]) of
        [] -> Right expr
        errs -> Left $ map (toException p) errs
    _ -> Left errs

    where
        toException :: Path -> Expression -> ErrorKind
        toException p (Error t why) = UE.Parsing $ UE.makeError p (tokenPos t) why
        toException _ _ = error "Is is really an error bro?"


-- |  used for debug version
replLexparseExpr :: String -> Either [ErrorKind] Expression
replLexparseExpr = lexparseExpr "stdin"
}